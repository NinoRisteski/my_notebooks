{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch\n",
    "%pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Data Module for PyTorch Lightning\n",
    "\n",
    "class BaseDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=32, split=0.8, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Get the dataset using the get_dataset method (to be implemented in subclasses)\n",
    "        self.ds_x, self.ds_y = self.get_dataset(*args, **kwargs)\n",
    "        \n",
    "        # Create a random permutation of indices to shuffle the dataset\n",
    "        # This ensures that the data is randomly ordered, which is important for training\n",
    "        shuffler = np.random.permutation(self.ds_x.shape[0])\n",
    "        \n",
    "        # Shuffle both input features (ds_x) and labels (ds_y) using the same permutation\n",
    "        # This maintains the correspondence between inputs and labels\n",
    "        self.ds_x = self.ds_x[shuffler]\n",
    "        self.ds_y = self.ds_y[shuffler]\n",
    "        \n",
    "        # Set the batch size for data loading\n",
    "        # This determines how many samples will be processed at once during training\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Calculate the split index for train/validation sets\n",
    "        # split is a float between 0 and 1, representing the proportion of data for training\n",
    "        # This allows for flexible dataset splitting\n",
    "        self.split = int(self.ds_x.shape[0] * split)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # Slice the training data from the beginning up to the split index\n",
    "        ds_X_train, ds_Y_train = self.ds_x[0:self.split], self.ds_y[0:self.split]\n",
    "        # Create and return a DataLoader with zipped training data and labels\n",
    "        # This DataLoader will be used by PyTorch Lightning to fetch batches during training\n",
    "        return torch.utils.data.DataLoader(list(zip(ds_X_train, ds_Y_train)), batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # Slice the validation data from the split index to the end\n",
    "        ds_X_test, ds_Y_test = self.ds_x[self.split:], self.ds_y[self.split:]\n",
    "        # Create and return a DataLoader with zipped validation data and labels\n",
    "        # This DataLoader will be used by PyTorch Lightning to fetch batches during validation\n",
    "        return torch.utils.data.DataLoader(list(zip(ds_X_test, ds_Y_test)), batch_size=self.batch_size)\n",
    "    \n",
    "class ReverseDataModule(BaseDataModule):\n",
    "    def get_dataset(self, cnt=1000, seq_len=6):\n",
    "        # Generate a synthetic dataset for the reverse sequence task\n",
    "        # cnt: Number of samples in the dataset (default 1000)\n",
    "        # seq_len: Length of each sequence (default 6)\n",
    "        \n",
    "        # Create random integer sequences from 0 to 9\n",
    "        ds = np.random.randint(0, 10, size=(cnt, seq_len))\n",
    "        \n",
    "        # Return two arrays:\n",
    "        # 1. The original random sequences (ds)\n",
    "        # 2. The reversed sequences (ds[:, ::-1])\n",
    "        #    - [:, ::-1] reverses each sequence\n",
    "        #    - ravel() flattens the array\n",
    "        #    - reshape() reshapes it back to (cnt, seq_len)\n",
    "        # The reversed sequences serve as the target for the model to learn\n",
    "        return ds, ds[:, ::-1].ravel().reshape(cnt, seq_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
